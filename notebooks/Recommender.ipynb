{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6e47ff",
   "metadata": {},
   "source": [
    "# MovieLens Collaborative Filtering Recommender System\n",
    "\n",
    "This notebook builds a **production-ready recommendation system** using Spark ALS (Alternating Least Squares) to generate personalized movie recommendations.\n",
    "\n",
    "## What This Notebook Does\n",
    "\n",
    "- Load MovieLens ratings and movies from CSV (local or HDFS)\n",
    "- Clean and filter data (remove sparse users/movies)\n",
    "- Split data: 80% train, 10% validation, 10% test\n",
    "- Train ALS model with hyperparameter tuning (rank, regParam)\n",
    "- Evaluate model performance:\n",
    "  - **RMSE**: Prediction accuracy on test ratings\n",
    "  - **Precision@K and Recall@K**: Ranking quality for top-N recommendations\n",
    "- Generate personalized top-N recommendations for all users\n",
    "- Handle cold-start users with popularity baseline\n",
    "- Export precomputed artifacts for API serving:\n",
    "  - user_topn/: Top-100 recommendations per user with metadata\n",
    "  - popularity/: Popular movies for cold-start fallback\n",
    "  - movies_meta/: Movie metadata (title, genres, year)\n",
    "  - item_factors/: ALS latent factors for item similarity\n",
    "\n",
    "## Expected Runtime\n",
    "\n",
    "10-30 minutes (depending on dataset size and hardware)\n",
    "\n",
    "## Outputs\n",
    "\n",
    "All artifacts saved to outputs/ directory in Parquet format for efficient API loading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa33cfcc",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df4f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import os\n",
    "\n",
    "# Configuration\n",
    "DATA_DIR = \"../data/movielens/32m\"\n",
    "OUTPUT_DIR = \"../outputs\"\n",
    "MIN_USER_INTERACTIONS = 20\n",
    "MIN_MOVIE_INTERACTIONS = 20\n",
    "N_RECS = 100\n",
    "K = 10  # for Precision@K and Recall@K\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee27b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"MovieLens-Recommender\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(f\"Number of cores: {spark.sparkContext.defaultParallelism}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6efd52",
   "metadata": {},
   "source": [
    "## 2. Load and Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a89610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ratings\n",
    "ratings_raw = spark.read.csv(\n",
    "    f\"{DATA_DIR}/ratings.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "print(f\"Total ratings: {ratings_raw.count():,}\")\n",
    "ratings_raw.printSchema()\n",
    "ratings_raw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee98f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load movies\n",
    "movies_raw = spark.read.csv(\n",
    "    f\"{DATA_DIR}/movies.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "print(f\"Total movies: {movies_raw.count():,}\")\n",
    "movies_raw.printSchema()\n",
    "movies_raw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4579ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean ratings: cast to proper types\n",
    "ratings = ratings_raw.select(\n",
    "    F.col(\"userId\").cast(IntegerType()),\n",
    "    F.col(\"movieId\").cast(IntegerType()),\n",
    "    F.col(\"rating\").cast(FloatType()),\n",
    "    F.col(\"timestamp\").cast(IntegerType())\n",
    ").dropna()\n",
    "\n",
    "print(f\"Cleaned ratings: {ratings.count():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5322ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out sparse users and movies\n",
    "user_counts = ratings.groupBy(\"userId\").count()\n",
    "active_users = user_counts.filter(F.col(\"count\") >= MIN_USER_INTERACTIONS).select(\"userId\")\n",
    "\n",
    "movie_counts = ratings.groupBy(\"movieId\").count()\n",
    "popular_movies = movie_counts.filter(F.col(\"count\") >= MIN_MOVIE_INTERACTIONS).select(\"movieId\")\n",
    "\n",
    "ratings_filtered = ratings \\\n",
    "    .join(active_users, \"userId\", \"inner\") \\\n",
    "    .join(popular_movies, \"movieId\", \"inner\")\n",
    "\n",
    "print(f\"Filtered ratings: {ratings_filtered.count():,}\")\n",
    "print(f\"Unique users: {ratings_filtered.select('userId').distinct().count():,}\")\n",
    "print(f\"Unique movies: {ratings_filtered.select('movieId').distinct().count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc854cf",
   "metadata": {},
   "source": [
    "## 3. Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 80% train, 10% validation, 10% test\n",
    "train_val, test = ratings_filtered.randomSplit([0.9, 0.1], seed=42)\n",
    "train, val = train_val.randomSplit([0.89, 0.11], seed=42)  # 0.9 * 0.89 ≈ 0.8\n",
    "\n",
    "train.cache()\n",
    "val.cache()\n",
    "test.cache()\n",
    "\n",
    "print(f\"Train: {train.count():,}\")\n",
    "print(f\"Validation: {val.count():,}\")\n",
    "print(f\"Test: {test.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd60b98",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3186a645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grid\n",
    "param_grid = [\n",
    "    {\"rank\": 10, \"regParam\": 0.01},\n",
    "    {\"rank\": 10, \"regParam\": 0.1},\n",
    "    {\"rank\": 20, \"regParam\": 0.01},\n",
    "    {\"rank\": 20, \"regParam\": 0.1},\n",
    "    {\"rank\": 50, \"regParam\": 0.01},\n",
    "]\n",
    "\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "best_rmse = float(\"inf\")\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "print(\"Starting hyperparameter search...\\n\")\n",
    "\n",
    "for params in param_grid:\n",
    "    print(f\"Training with rank={params['rank']}, regParam={params['regParam']}\")\n",
    "    \n",
    "    als = ALS(\n",
    "        maxIter=10,\n",
    "        rank=params[\"rank\"],\n",
    "        regParam=params[\"regParam\"],\n",
    "        userCol=\"userId\",\n",
    "        itemCol=\"movieId\",\n",
    "        ratingCol=\"rating\",\n",
    "        coldStartStrategy=\"drop\",\n",
    "        seed=42\n",
    "    )\n",
    "    \n",
    "    model = als.fit(train)\n",
    "    predictions = model.transform(val)\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "    \n",
    "    print(f\"  Validation RMSE: {rmse:.4f}\")\n",
    "    \n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_params = params\n",
    "        best_model = model\n",
    "        print(f\"  *** New best model! ***\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best validation RMSE: {best_rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaaff38",
   "metadata": {},
   "source": [
    "## 5. Final Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model on train+val using best parameters\n",
    "als_final = ALS(\n",
    "    maxIter=10,\n",
    "    rank=best_params[\"rank\"],\n",
    "    regParam=best_params[\"regParam\"],\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\",\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "model_final = als_final.fit(train_val)\n",
    "\n",
    "print(\"Final model trained on train+validation data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6201b885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_predictions = model_final.transform(test)\n",
    "rmse_evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "test_rmse = rmse_evaluator.evaluate(test_predictions)\n",
    "print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"\\nInterpretation: On average, predictions are off by {test_rmse:.2f} stars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ef1336",
   "metadata": {},
   "source": [
    "## 6. Precision@K and Recall@K Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a188e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top-K recommendations for test users\n",
    "test_users = test.select(\"userId\").distinct()\n",
    "user_recs = model_final.recommendForUserSubset(test_users, K)\n",
    "\n",
    "# Explode recommendations\n",
    "user_recs_exploded = user_recs.select(\n",
    "    \"userId\",\n",
    "    F.explode(\"recommendations\").alias(\"rec\")\n",
    ").select(\n",
    "    \"userId\",\n",
    "    F.col(\"rec.movieId\").alias(\"movieId\"),\n",
    "    F.col(\"rec.rating\").alias(\"score\")\n",
    ")\n",
    "\n",
    "# Get relevant items (movies rated >= 4.0 in test set)\n",
    "relevant_items = test.filter(F.col(\"rating\") >= 4.0).select(\"userId\", \"movieId\")\n",
    "\n",
    "# Calculate precision and recall\n",
    "recommended_items = user_recs_exploded.select(\"userId\", \"movieId\")\n",
    "\n",
    "# True positives: recommended AND relevant\n",
    "tp = recommended_items.join(relevant_items, [\"userId\", \"movieId\"], \"inner\") \\\n",
    "    .groupBy(\"userId\").count().withColumnRenamed(\"count\", \"tp\")\n",
    "\n",
    "# Total recommended per user\n",
    "total_rec = recommended_items.groupBy(\"userId\").count().withColumnRenamed(\"count\", \"total_rec\")\n",
    "\n",
    "# Total relevant per user\n",
    "total_rel = relevant_items.groupBy(\"userId\").count().withColumnRenamed(\"count\", \"total_rel\")\n",
    "\n",
    "# Join and calculate metrics\n",
    "metrics_df = total_rec.join(total_rel, \"userId\", \"inner\").join(tp, \"userId\", \"left_outer\").fillna(0)\n",
    "\n",
    "metrics_df = metrics_df.withColumn(\n",
    "    \"precision\", F.col(\"tp\") / F.col(\"total_rec\")\n",
    ").withColumn(\n",
    "    \"recall\", F.col(\"tp\") / F.col(\"total_rel\")\n",
    ")\n",
    "\n",
    "avg_precision = metrics_df.agg(F.avg(\"precision\")).collect()[0][0]\n",
    "avg_recall = metrics_df.agg(F.avg(\"recall\")).collect()[0][0]\n",
    "\n",
    "print(f\"Precision@{K}: {avg_precision:.4f}\")\n",
    "print(f\"Recall@{K}: {avg_recall:.4f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "print(f\"  - {avg_precision*100:.1f}% of top-{K} recommendations are relevant (rated ≥4.0)\")\n",
    "print(f\"  - We capture {avg_recall*100:.1f}% of all relevant items in top-{K}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd5619c",
   "metadata": {},
   "source": [
    "## 7. Generate Recommendations for All Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91737f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top-N recommendations for all users\n",
    "all_users = ratings_filtered.select(\"userId\").distinct()\n",
    "all_user_recs = model_final.recommendForUserSubset(all_users, N_RECS)\n",
    "\n",
    "print(f\"Generated top-{N_RECS} recommendations for {all_user_recs.count():,} users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0c391b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare recommendations with movie metadata\n",
    "user_recs_ranked = all_user_recs.select(\n",
    "    \"userId\",\n",
    "    F.explode(\"recommendations\").alias(\"rec\")\n",
    ").select(\n",
    "    \"userId\",\n",
    "    F.col(\"rec.movieId\").alias(\"movieId\"),\n",
    "    F.col(\"rec.rating\").alias(\"score\")\n",
    ")\n",
    "\n",
    "# Add rank within user\n",
    "window_spec = Window.partitionBy(\"userId\").orderBy(F.col(\"score\").desc())\n",
    "user_recs_ranked = user_recs_ranked.withColumn(\"rank\", F.row_number().over(window_spec))\n",
    "\n",
    "# Join with movie titles\n",
    "movies_clean = movies_raw.select(\n",
    "    F.col(\"movieId\").cast(IntegerType()),\n",
    "    F.col(\"title\"),\n",
    "    F.col(\"genres\")\n",
    ")\n",
    "\n",
    "user_recs_with_titles = user_recs_ranked.join(movies_clean, \"movieId\", \"left\")\n",
    "\n",
    "print(\"Sample recommendations with metadata:\")\n",
    "user_recs_with_titles.filter(F.col(\"userId\") == 1).orderBy(\"rank\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d05181",
   "metadata": {},
   "source": [
    "## 8. Popularity Baseline for Cold Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6549ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate popularity baseline (most-rated movies)\n",
    "popularity = ratings_filtered.groupBy(\"movieId\").agg(\n",
    "    F.count(\"rating\").alias(\"interaction_count\"),\n",
    "    F.avg(\"rating\").alias(\"avg_rating\")\n",
    ").join(movies_clean, \"movieId\", \"inner\")\n",
    "\n",
    "# Filter for high-quality popular movies\n",
    "popularity_threshold = 100\n",
    "popular_movies = popularity \\\n",
    "    .filter(F.col(\"interaction_count\") >= popularity_threshold) \\\n",
    "    .filter(F.col(\"avg_rating\") >= 3.5) \\\n",
    "    .orderBy(F.col(\"interaction_count\").desc()) \\\n",
    "    .limit(N_RECS)\n",
    "\n",
    "print(f\"Top {N_RECS} popular movies for cold-start fallback:\")\n",
    "popular_movies.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f42b15",
   "metadata": {},
   "source": [
    "## 9. Export Artifacts for Production API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f35a612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Define output paths\n",
    "output_path_user_recs = f\"{OUTPUT_DIR}/user_topn\"\n",
    "output_path_popular = f\"{OUTPUT_DIR}/popularity\"\n",
    "output_path_movies = f\"{OUTPUT_DIR}/movies_meta\"\n",
    "output_path_item_factors = f\"{OUTPUT_DIR}/item_factors\"\n",
    "\n",
    "print(f\"Export paths:\")\n",
    "print(f\"  - User recommendations: {output_path_user_recs}\")\n",
    "print(f\"  - Popular movies: {output_path_popular}\")\n",
    "print(f\"  - Movie metadata: {output_path_movies}\")\n",
    "print(f\"  - Item factors: {output_path_item_factors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6295ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export user recommendations\n",
    "user_recs_with_titles.coalesce(1).write.mode(\"ignore\").parquet(output_path_user_recs)\n",
    "print(f\"✓ Exported user recommendations to {output_path_user_recs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adf6268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export popularity baseline\n",
    "popular_movies.coalesce(1).write.mode(\"ignore\").parquet(output_path_popular)\n",
    "print(f\"✓ Exported popularity baseline to {output_path_popular}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa95cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export movie metadata\n",
    "movies_clean.coalesce(1).write.mode(\"ignore\").parquet(output_path_movies)\n",
    "print(f\"✓ Exported movie metadata to {output_path_movies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export item factors for similarity computation\n",
    "item_factors = model_final.itemFactors\n",
    "item_factors.coalesce(1).write.mode(\"ignore\").parquet(output_path_item_factors)\n",
    "print(f\"✓ Exported item factors to {output_path_item_factors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2351ef",
   "metadata": {},
   "source": [
    "## 10. Verify Exports and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd31e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify exports by reading them back\n",
    "print(\"Verifying exports...\\n\")\n",
    "\n",
    "user_recs_check = spark.read.parquet(output_path_user_recs)\n",
    "print(f\"User recommendations: {user_recs_check.count():,} records\")\n",
    "\n",
    "popular_check = spark.read.parquet(output_path_popular)\n",
    "print(f\"Popular movies: {popular_check.count():,} records\")\n",
    "\n",
    "movies_check = spark.read.parquet(output_path_movies)\n",
    "print(f\"Movie metadata: {movies_check.count():,} records\")\n",
    "\n",
    "factors_check = spark.read.parquet(output_path_item_factors)\n",
    "print(f\"Item factors: {factors_check.count():,} records\")\n",
    "\n",
    "print(\"\\n✓ All artifacts successfully exported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bff054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"=\"*60)\n",
    "print(\"RECOMMENDATION SYSTEM SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModel Configuration:\")\n",
    "print(f\"  - Algorithm: ALS (Alternating Least Squares)\")\n",
    "print(f\"  - Rank: {best_params['rank']}\")\n",
    "print(f\"  - Regularization: {best_params['regParam']}\")\n",
    "print(f\"\\nPerformance Metrics:\")\n",
    "print(f\"  - Test RMSE: {test_rmse:.4f}\")\n",
    "print(f\"  - Precision@{K}: {avg_precision:.4f}\")\n",
    "print(f\"  - Recall@{K}: {avg_recall:.4f}\")\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  - Total ratings: {ratings_filtered.count():,}\")\n",
    "print(f\"  - Unique users: {ratings_filtered.select('userId').distinct().count():,}\")\n",
    "print(f\"  - Unique movies: {ratings_filtered.select('movieId').distinct().count():,}\")\n",
    "print(f\"\\nGenerated Artifacts:\")\n",
    "print(f\"  - Top-{N_RECS} recommendations per user\")\n",
    "print(f\"  - {popular_check.count()} popular movies for cold-start\")\n",
    "print(f\"  - Movie metadata and item factors\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Ready for production deployment via FastAPI!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df76b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark session\n",
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
