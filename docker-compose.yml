services:
  namenode:
    image: apache/hadoop:3.3.6
    container_name: namenode
    environment:
      - HADOOP_SERVICE=namenode
    ports:
      - "9870:9870"  # NameNode web UI
      - "8020:8020"  # NameNode RPC (fs.defaultFS)
    command: ["bash", "-lc", "hdfs namenode -format -force -nonInteractive || true; hdfs --daemon start namenode; tail -F $HADOOP_HOME/logs/*namenode*.log"]
    healthcheck:
      test: ["CMD-SHELL", "jps | grep -q NameNode"]
      interval: 10s
      timeout: 5s
      retries: 12

  datanode:
    image: apache/hadoop:3.3.6
    container_name: datanode
    environment:
      - HADOOP_SERVICE=datanode
    depends_on:
      namenode:
        condition: service_healthy
    ports:
      - "9864:9864"  # DataNode web UI
    command: ["bash", "-lc", "hdfs --daemon start datanode; tail -F $HADOOP_HOME/logs/*datanode*.log"]
    healthcheck:
      test: ["CMD-SHELL", "jps | grep -q DataNode"]
      interval: 10s
      timeout: 5s
      retries: 12

  jupyter:
    image: jupyter/pyspark-notebook
    container_name: jupyter
    ports:
      - "8888:8888"
    volumes:
      - ./:/home/jovyan/work
    command: >
      start.sh jupyter notebook --NotebookApp.token=''
      --NotebookApp.password=''
      --NotebookApp.disable_check_xsrf=True
    environment:
      - JUPYTER_ENABLE_LAB=yes
    depends_on:
      - namenode
      - datanode
  spark-master:
    image: apache/spark:3.5.6
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master --host spark-master --port 7077 --webui-port 8080

  spark-worker:
    image: apache/spark:3.5.6
    container_name: spark-worker
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077 --webui-port 8081


volumes:
  hadoop_namenode:
  hadoop_datanode:
